{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Evaluate quality metrics for each model\n",
    "\n",
    "training and test sets confusion matrix, precision, recall, F1score, PR curve, ROC curve, AUC"
   ],
   "id": "4b3ba9b7b80bcaa9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model **malicious_benign_classification**",
   "id": "fed6a3742f5cf36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The quality metrics for the model **malicious_benign_classification.py** indicate perfect performance on both the training and test sets. Here's what each metric means:\n",
    "\n",
    "- **Confusion Matrix**: \n",
    "  - Train: The model correctly predicted all 85 instances of the negative class (True Negatives) and all 8 instances of the positive class (True Positives).\n",
    "  - Test: Similarly, the model correctly predicted all 22 instances of the negative class and all 2 instances of the positive class.\n",
    "\n",
    "- **Precision**: \n",
    "  - Train: Precision is 1.0, indicating that all the instances predicted as positive are indeed positive.\n",
    "  - Test: Similarly, precision is 1.0 for the test set, meaning all positive predictions are correct.\n",
    "\n",
    "- **Recall**: \n",
    "  - Train: Recall is 1.0, indicating that the model correctly identified all positive instances out of all actual positives.\n",
    "  - Test: The test set recall is also 1.0, meaning the model correctly identified all positive instances in the test data.\n",
    "\n",
    "- **F1 Score**: \n",
    "  - Train: F1 score is 1.0, which is the harmonic mean of precision and recall. It indicates perfect balance between precision and recall.\n",
    "  - Test: F1 score is 1.0 for the test set as well.\n",
    "\n",
    "- **AUC (Area Under the ROC Curve)**: \n",
    "  - Train: AUC is 1.0, indicating perfect separability between the two classes.\n",
    "  - Test: Similarly, AUC is 1.0 for the test set.\n",
    "\n",
    "These results suggest that the model is performing exceptionally well and is likely overfitting the data, as it achieves perfect scores on both training and test sets.\n"
   ],
   "id": "f0c3f12dca77884b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model **random_classification.py** \n",
   "id": "a43230291282b8a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "65349f25e6e353b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Model **random_classification.py** seems to perform exceptionally well across various quality metrics:\n",
    "\n",
    "1. **Confusion Matrix**: Both on the training and test data, the model predicts all instances correctly, indicating no false positives or false negatives. This suggests that the model has learned the patterns in the data very well.\n",
    "\n",
    "2. **Precision**: Precision measures the proportion of true positive predictions among all positive predictions. With a precision of 1.0 for both training and test data, it means that all the positive predictions made by the model are indeed correct.\n",
    "\n",
    "3. **Recall (Sensitivity)**: Recall measures the proportion of true positives that were correctly identified by the model among all actual positives. Again, with a score of 1.0 for both training and test data, it means the model is capturing all positive instances correctly.\n",
    "\n",
    "4. **F1 Score**: F1 Score is the harmonic mean of precision and recall, balancing both metrics. A score of 1.0 indicates perfect precision and recall, which in turn suggests an excellent balance between precision and recall.\n",
    "\n",
    "5. **AUC (Area Under the ROC Curve)**: AUC measures the area under the Receiver Operating Characteristic curve, which plots the true positive rate against the false positive rate. An AUC of 1.0 indicates perfect performance, where the model has a perfect true positive rate while maintaining a false positive rate of 0.\n",
    "\n",
    "Overall, based on these metrics, the model seems to be performing flawlessly on both the training and test data, indicating that it has learned the patterns in the data very well and generalizes well to unseen data."
   ],
   "id": "ea460df3d582783c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
